{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAyt2NDiios7",
        "outputId": "4ac9c0c3-786c-4906-d3d3-a2cf3284ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-05 05:33:39--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  15.4MB/s    in 6.6s    \n",
            "\n",
            "2023-07-05 05:33:46 (9.21 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import dlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "yXN0HQb7l9Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def helper(img_path, mask):\n",
        "  image = cv2.imread(img_path)\n",
        "  result = cv2.bitwise_and(image, mask)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "46J7lw5EkVOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v1VYxCMahao_",
        "outputId": "820c9718-486d-413c-e630-60b4915ec446"
      },
      "outputs": [],
      "source": [
        "directory = \"/content/drive/MyDrive/Clubbed_Images_parent/Clubbed images\"\n",
        "save_to = \"/content/drive/MyDrive/Filtered_Human_Images/\"\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    club_directory = os.path.join(directory, filename)\n",
        "    # print(club_directory)\n",
        "    for filename2 in os.listdir(club_directory):\n",
        "\n",
        "      if \"8\" in filename2.split(\"-\"):\n",
        "        name1 = os.path.join(club_directory, filename2)\n",
        "      elif \"32\" in filename2.split(\"-\"):\n",
        "        name2 = os.path.join(club_directory, filename2)\n",
        "      else:\n",
        "        # Load the image\n",
        "        image = cv2.imread(os.path.join(club_directory, filename2))\n",
        "        # print(image.shape)\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Initialize the dlib face detector and facial landmarks predictor\n",
        "        detector = dlib.get_frontal_face_detector()\n",
        "        # Download the .dat file from the internet.\n",
        "        predictor = dlib.shape_predictor('/content/drive/MyDrive/Bank_dataset/shape_predictor_194_face_landmarks.dat')  # Replace with the path to your shape predictor model\n",
        "\n",
        "        # Detect faces in the grayscale image\n",
        "        faces = detector(gray)\n",
        "\n",
        "        # Iterate over the detected faces and extract the facial region\n",
        "        for face in faces:\n",
        "          # Predict facial landmarks for the current face\n",
        "          landmarks = predictor(gray, face)\n",
        "\n",
        "          # Create a numpy array of the facial landmarks' coordinates\n",
        "          landmarks_array = np.zeros((194, 2), dtype=int)\n",
        "          for i in range(194):\n",
        "            if i==0 or i==134:\n",
        "              landmarks_array[i] = (landmarks.part(i).x, landmarks.part(i).y-125)\n",
        "            else:\n",
        "              landmarks_array[i] = (landmarks.part(i).x, landmarks.part(i).y)\n",
        "\n",
        "          # Define the forehead region based on the facial landmarks\n",
        "          # Define the region of interest (ROI) as the convex hull of the facial landmarks\n",
        "          hull = cv2.convexHull(landmarks_array)\n",
        "\n",
        "          # Create a mask of the same size as the original image and fill it with white\n",
        "          mask = np.zeros_like(image)\n",
        "          cv2.fillConvexPoly(mask, hull, (255, 255, 255))\n",
        "\n",
        "          # Apply the mask to the original image\n",
        "          result = cv2.bitwise_and(image, mask)\n",
        "\n",
        "\n",
        "        # Display the result\n",
        "        # cv2_imshow('Original Image', image)\n",
        "        cv2_imshow(image)\n",
        "        cv2_imshow(result)\n",
        "\n",
        "        cv2.imwrite(save_to + filename2, result)\n",
        "\n",
        "    cv2.imwrite(save_to + name1.split(\"/\")[-1], helper(name1, mask))\n",
        "    cv2.imwrite(save_to + name2.split(\"/\")[-1], helper(name2, mask))\n"
      ]
    }
  ]
}